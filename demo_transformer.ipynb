{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPRM6Nq2fsUf",
        "outputId": "19a56b2b-3481-43d9-f60b-5b6cd3e5a992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras_nlp\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ezsMS9FCgpKm"
      },
      "outputs": [],
      "source": [
        "path_tales = 'bajki/'\n",
        "\n",
        "texts = ''\n",
        "for index, path in enumerate(os.listdir(path_tales)):\n",
        "    text = ''\n",
        "    with open(path_tales + path, encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "        texts += text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybwLPQsfkkJY",
        "outputId": "e5ecd6c7-fb78-443a-fa81-fe5caae7442f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "100%|██████████| 85/85 [00:19<00:00,  4.37it/s]\n"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "def clean_text(txt):\n",
        "    # Remove punctuation\n",
        "    txt = \"\".join(v for v in txt if v not in string.punctuation and '\\n' not in v)\n",
        "\n",
        "    # Remove non-alphanumeric characters (including special characters)\n",
        "    txt = re.sub(r'[^a-zA-Ząćęłńóśźż\\s]', '', txt)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    txt = txt.lower()\n",
        "\n",
        "    return txt\n",
        "\n",
        "path_tales = 'gdrive/MyDrive/bajki/'\n",
        "sentences = []\n",
        "\n",
        "for filename in tqdm.tqdm(os.listdir(path_tales)):\n",
        "    with open(path_tales + filename, 'r', encoding='utf-8') as f:\n",
        "        tale_text = f.read()\n",
        "        tale_text = sent_tokenize(tale_text)\n",
        "\n",
        "        sentences.extend([clean_text(l) for l in tale_text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1DiiWAUjMHD",
        "outputId": "6017bb1a-4514-45c5-9bae-fd063070dc26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['pewna uboga wdowa mieszkała w samotnej chatce a przed tą chatką był ogródek w którym rosły dwa krzaki róż jedne róże białe drugie czerwone',\n",
              " 'wdowa miała dwie córeczki podobne do obu krzaków róż',\n",
              " 'jedna zwała się białośnieżką a druga różanką',\n",
              " 'dziewczątka były tak pobożne i dobre tak pracowite i roztropne że chyba drugich takich dzieci nie było na świecie ale białośnieżka była łagodniejszą niż różanka',\n",
              " 'różanka wolała skakać po łąkach i polach rwała kwiatki i goniła ptaszyny leśne a białośnieżka siadywała w domu przy matce pomagała jej w gospodarstwie albo czytywała jej książki gdy nic innego nie było do roboty',\n",
              " 'obie dziewczynki tak bardzo się kochały że zawsze idąc razem trzymały się za rączki a gdy białośnieżka mówiła my się nigdy nie rozstaniemy różanka odpowiadała tym co ma jedna musi się i druga podzielićnieraz biegały same po lesie i zbierały czerwone jagody żadne zwierzę nie robiło im nic złego ale przychodziły do nich z całym zaufaniem zajączek jadł z ich rąk kapustę sarna skubała trawkę tuż przy nich jeleń wysoko wyskakiwał obok ptaki zostawały na gałęziach i wyśpiewywały wszystkie swoje trele',\n",
              " 'dziewczęta nie miewały żadnych przygód jeżeli się zapóźniły w lesie a noc je zaskoczyła to kładły się jedna przy drugiej na murawie i zasypiały aż do ranka a matka wiedziała o tym i nie trwożyła się o nie',\n",
              " 'pewnego razu gdy nocowały w lesie a świt różany je zbudził spostrzegły śliczne dziecko w białej błyszczącej sukieneczce siedzące przy ich posłaniu i spoglądające na nie bardzo życzliwie',\n",
              " 'nic nie mówiąc odeszło potem w głąb lasu a gdy się obejrzały zauważyły że leżą tuż nad głęboką przepaścią że gdyby były w ciemnościach i stąpiły jeszcze parę kroków to byłyby w tę przepaść wpadły',\n",
              " 'a matka im powiedziała że musiał to być anioł stróż który czuwa nad dobrymi dziećmi']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "d5Pr50rsjVnk"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.shuffle(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yHIWyJD5mAzo"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Tokenize the sentences and count word frequencies\n",
        "word_counts = Counter()\n",
        "for sentence in sentences:\n",
        "    words = sentence.split()\n",
        "    word_counts.update(words)\n",
        "\n",
        "# Select the top 50,000 most frequent words\n",
        "top_words = set(word for word, _ in word_counts.most_common(50000))\n",
        "\n",
        "# Replace the sentences with only the top words\n",
        "new_sentences = []\n",
        "for sentence in sentences:\n",
        "    words = sentence.split()\n",
        "    selected_words = [word for word in words if word in top_words]\n",
        "    new_sentences.append(\" \".join(selected_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLq-EtrCnCCn",
        "outputId": "ab02e535-24d4-4d97-ccc1-0126290c02ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['nad ludźmi odparła',\n",
              " 'wtem pies nozdrza zapuścił w dół powąchał mocno podniósł się i szczeknął jakby w głąb jamy pokazywał chłopcu',\n",
              " 'to niepodobna mruczał scrooge żebym przespał dzień i część drugiej nocy',\n",
              " 'widzę',\n",
              " 'ho',\n",
              " 'jesteśmy',\n",
              " 'postanowił być dumny do końca',\n",
              " 'to okropne myślał przeprowadzać operację w takich warunkach',\n",
              " 'natychmiast do powrotu wszelka chęć wszyscy wołają wojny chęć w nich pała',\n",
              " 'ujrzałem światło i zaszedłem tutaj aż pod tę chałupę']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_sentences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fPeHUzTCjirR"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    sentence = tf.strings.lower(input_string)\n",
        "    sentence = tf.strings.regex_replace(sentence, \"\\n\", \" \")\n",
        "    return sentence\n",
        "\n",
        "maxlen = 50\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize = custom_standardization,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=maxlen + 1,\n",
        ")\n",
        "\n",
        "vectorize_layer.adapt(new_sentences)\n",
        "vocab = vectorize_layer.get_vocabulary()\n",
        "index_lookup = dict(zip(range(len(vocab)), vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CnwrUd8rNIsu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model_filename = 'transformer'  # Example filename for epoch 1\n",
        "\n",
        "exp = load_model(model_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUpuT1r5NUHO",
        "outputId": "13a41691-c192-440f-94b4-2b87d0f3ad31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample text:\n",
            "dawno dawno temu nie mogę powiedzieć ale i ja mam  do tego wszystkiego   co   innego do tego uczynić bo i nie mam  czasu i w tej porze planów zapowiedział że go nie ma do stracenia ale w pamięci   i że jest  dla niej i...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def sample_token(logits):\n",
        "    logits, indices = tf.math.top_k(logits, k=5, sorted=True)\n",
        "    indices = np.asarray(indices).astype(\"int32\")\n",
        "    preds = keras.activations.softmax(tf.expand_dims(logits, 0))[0]\n",
        "    preds = np.asarray(preds).astype(\"float32\")\n",
        "    return np.random.choice(indices, p=preds)\n",
        "\n",
        "decoded_sample = 'dawno dawno temu'\n",
        "\n",
        "for i in range(50):\n",
        "    tokenized_prompt = vectorize_layer([decoded_sample])[:, :-1]\n",
        "    predictions = exp.predict([tokenized_prompt], verbose=0)\n",
        "\n",
        "    sample_index = len(decoded_sample.strip().split())-1\n",
        "\n",
        "    sampled_token = sample_token(predictions[0][sample_index])\n",
        "    sampled_token = index_lookup[sampled_token]\n",
        "    decoded_sample += \" \" + sampled_token\n",
        "\n",
        "print(f\"\\nSample text:\\n{decoded_sample}...\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
